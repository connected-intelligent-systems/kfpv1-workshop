{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with the YOLO Brain MRI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from ultralytics.utils.ops import non_max_suppression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = Image.open(image)\n",
    "    image = image.resize((256, 256))\n",
    "\n",
    "    # BGR to BCHW, (n, 3, h, w)\n",
    "    image = np.array(image)[:, :, :3]\n",
    "    image = image[:, :, ::-1]\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :, :, :]\n",
    "    image = torch.tensor(image.copy(), dtype=torch.float32)\n",
    "    image = image / 255.0 \n",
    "      \n",
    "    # Create request message to be sent to the predictor\n",
    "    message_data = {}\n",
    "    inputs = {}\n",
    "    message_data[\"inputs\"] = []\n",
    "    inputs[\"name\"] = \"images\"\n",
    "    inputs[\"shape\"] = image.shape\n",
    "    inputs[\"datatype\"] = \"FP32\"  # as the given onnx model expects float32\n",
    "    inputs[\"data\"] = image.tolist()\n",
    "    message_data[\"inputs\"].append(inputs)\n",
    "    \n",
    "    return message_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Inference Service and Images for tumor prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Configure Variables for the Predictor URL and Image Directory\n",
    "image_dir = \"../brain-mri/notebooks_data_preparation/yolo/datasets/yolo_mri_brain/test/images\"\n",
    "predictor_url = f\"https://brain-mri-predictor-workshop.10-101-20-33.sslip.io/v2/models/brain-mri/infer\"\n",
    "\n",
    "# get images from the image directory\n",
    "images = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "# choose 5 random images\n",
    "import random\n",
    "images = random.sample(images, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for image in images:\n",
    "    # preprocess image\n",
    "    message_data = preprocess(image)\n",
    "\n",
    "    # Call predictor\n",
    "    request_headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    # suppress the warning for now\n",
    "    import warnings\n",
    "\n",
    "    # Suppress all warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    response = requests.post(\n",
    "        predictor_url, headers=request_headers, data=json.dumps(message_data), verify=False\n",
    "    ) \n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    response_message = json.loads(response.text)\n",
    "    # convert list to tensor\n",
    "    output = torch.tensor(response_message[\"outputs\"][0][\"data\"]).reshape(response_message[\"outputs\"][0][\"shape\"])\n",
    "    # Apply non-max suppression\n",
    "    prediction = non_max_suppression(prediction=output, conf_thres=0.5, iou_thres=0.5, classes=0)\n",
    "    predictions.append(prediction[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# plot images in a grid\n",
    "num_im_per_row = 5\n",
    "num_rows = len(images) // num_im_per_row\n",
    "fig, axs = plt.subplots(num_rows, num_im_per_row, figsize=(num_im_per_row*5, num_rows*5))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.imshow(Image.open(images[i]))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Prediction: {predictions[i].shape[0]}\")\n",
    "    # plot bounding boxes\n",
    "    for box in predictions[i]:\n",
    "        x1, y1, x2, y2 = box[:4]\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        # add confidence score\n",
    "        ax.text(x1, y1, f\"{box[4]:.2f}\", color='red')\n",
    "plt.show()\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
